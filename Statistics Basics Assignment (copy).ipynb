{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Statistics Basics Assignment",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 1. Explain the different types of data (qualitative and quantitative) and provide examples of each. Discuss nominal, ordinal, interval, and ratio scales.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "In statistics, data can be classified into different types based on their nature and how they can be measured. The two primary categories are **qualitative** (categorical) and **quantitative** (numerical) data. \n\n## **1. Types of Data**\n\n### **A. Qualitative Data (Categorical Data)**\n- **Definition**: Qualitative data describes qualities, attributes, or categories that cannot be measured numerically. It is used to classify data into groups or categories based on certain characteristics.\n- **Examples**:\n  - **Color**: Red, Green, Blue\n  - **Gender**: Male, Female, Non-binary\n  - **Brand**: Nike, Adidas, Puma\n\n#### **Subtypes of Qualitative Data**:\n1. **Nominal Data**:\n   - **Definition**: Data that represents categories without any specific order or ranking.\n   - **Characteristics**:\n     - No meaningful order\n     - Used to label variables without quantitative value\n   - **Examples**:\n     - Eye color (Brown, Blue, Green)\n     - Marital status (Single, Married, Divorced)\n\n2. **Ordinal Data**:\n   - **Definition**: Data that represents categories with a meaningful order or ranking but without equal intervals between categories.\n   - **Characteristics**:\n     - Has a specific order\n     - Differences between ranks are not measurable\n   - **Examples**:\n     - Customer satisfaction ratings (Poor, Fair, Good, Excellent)\n     - Education level (High School, Bachelor's, Master's, PhD)\n\n### **B. Quantitative Data (Numerical Data)**\n- **Definition**: Quantitative data represents numerical values that can be counted or measured. It is used to quantify attributes.\n- **Examples**:\n  - **Age**: 23 years, 45 years\n  - **Height**: 5'8\", 6'0\"\n  - **Weight**: 60 kg, 75 kg\n\n#### **Subtypes of Quantitative Data**:\n1. **Discrete Data**:\n   - **Definition**: Countable data with specific, fixed values, usually whole numbers.\n   - **Examples**:\n     - Number of students in a class (20, 25, 30)\n     - Number of cars in a parking lot (5, 10, 15)\n\n2. **Continuous Data**:\n   - **Definition**: Measurable data that can take any value within a range, often with decimals.\n   - **Examples**:\n     - Height (5.8 ft, 6.1 ft)\n     - Temperature (23.5°C, 25.7°C)\n\n---\n\n## **2. Levels of Measurement Scales**\n\nData can be further classified based on how it is measured. The **four levels of measurement** are: **Nominal, Ordinal, Interval,** and **Ratio**.\n\n### **A. Nominal Scale**\n- **Definition**: The nominal scale is used for labeling variables without any quantitative value or order. It categorizes data into distinct groups.\n- **Characteristics**:\n  - No inherent order\n  - Cannot perform mathematical operations\n- **Examples**:\n  - Blood Type (A, B, AB, O)\n  - Gender (Male, Female)\n\n### **B. Ordinal Scale**\n- **Definition**: The ordinal scale categorizes data with a meaningful order or ranking but without equal intervals between categories.\n- **Characteristics**:\n  - Ordered data\n  - Differences between ranks are not measurable\n- **Examples**:\n  - Class rank (1st, 2nd, 3rd)\n  - Survey ratings (Poor, Fair, Good, Excellent)\n\n### **C. Interval Scale**\n- **Definition**: The interval scale measures ordered data with equal intervals between values, but it does not have a true zero point.\n- **Characteristics**:\n  - Equal intervals between values\n  - No true zero (zero does not indicate \"none\")\n  - Allows addition and subtraction\n- **Examples**:\n  - Temperature in Celsius (0°C does not mean no temperature)\n  - Calendar years (2000, 2010, 2020)\n\n### **D. Ratio Scale**\n- **Definition**: The ratio scale measures ordered data with equal intervals and has a true zero point, allowing for meaningful comparisons of ratios.\n- **Characteristics**:\n  - Equal intervals between values\n  - Has a true zero (zero indicates the absence of the attribute)\n  - Allows all mathematical operations (addition, subtraction, multiplication, division)\n- **Examples**:\n  - Height (0 cm means no height)\n  - Weight (0 kg means no weight)\n  - Age (0 years indicates a newborn)\n\n---\n\n## **Summary Table of Measurement Scales**\n\n| Scale      | Order | Equal Intervals | True Zero | Examples                      |\n|------------|-------|-----------------|-----------|-------------------------------|\n| **Nominal**| No    | No              | No        | Gender, Blood Type            |\n| **Ordinal**| Yes   | No              | No        | Education Level, Survey Ratings|\n| **Interval**| Yes   | Yes             | No        | Temperature (°C, °F), Time    |\n| **Ratio**  | Yes   | Yes             | Yes       | Height, Weight, Age           |\n\n---\n\n## **Choosing the Appropriate Scale and Data Type**\n\n- **Nominal Scale**:\n  - Best for categorizing data without any meaningful order.\n  - Example: Analyzing the most common eye color in a group.\n\n- **Ordinal Scale**:\n  - Best for ranking or ordering data without assuming equal differences between ranks.\n  - Example: Survey results where customers rate satisfaction on a scale from 1 to 5.\n\n- **Interval Scale**:\n  - Best for measuring differences between values without a true zero.\n  - Example: Analyzing temperature changes over time in Celsius.\n\n- **Ratio Scale**:\n  - Best for measuring data with meaningful differences and a true zero.\n  - Example: Comparing the weights of different athletes.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 2. What are the measures of central tendency, and when should you use each? Discuss the mean, median, and mode with examples and situations where each is appropriate.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "#### Measures of Central Tendency are statistical metrics used to summarize a dataset by identifying a central point. The three most common measures of central tendency are mean, median, and mode.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Measures of Central Tendency** are statistical metrics used to summarize a dataset by identifying a central point. The three most common measures of central tendency are **mean**, **median**, and **mode**. Each has its own characteristics and is best used in different situations. Let's go through them step by step:\n\n## **1. Mean (Arithmetic Average)**\n### **Definition**:\nThe **mean** is the sum of all values in a dataset divided by the number of values. It represents the average of the dataset.\n\n### **Formula**:\n\\[\n\\text{Mean} = \\frac{\\sum x_i}{n}\n\\]\nWhere:\n- \\( \\sum x_i \\) = Sum of all data points\n- \\( n \\) = Number of data points\n\n### **Example**:\nSuppose we have the ages of a group of people: **[23, 25, 29, 30, 34]**\n- **Mean** = (23 + 25 + 29 + 30 + 34) / 5 = **28.2**\n\n### **When to Use**:\n- **Use the mean** when you have **continuous data** and no extreme outliers.\n- It provides a balanced central point but can be **sensitive to extreme values** (outliers).\n\n### **Example Situation**:\n- **Income Data**: In a homogeneous group, the mean income can give a good estimate of the average income.\n\n### **Limitations**:\n- If there are outliers (e.g., one person earning significantly more than others), the mean might not represent the data accurately.\n\n---\n\n## **2. Median**\n### **Definition**:\nThe **median** is the middle value in a dataset when it is arranged in ascending order. If there is an even number of data points, the median is the average of the two middle values.\n\n### **Steps to Calculate Median**:\n1. Sort the data in ascending order.\n2. If the number of data points (\\(n\\)) is **odd**, the median is the middle value.\n3. If \\(n\\) is **even**, the median is the average of the two middle values.\n\n### **Example**:\nFor the dataset **[23, 25, 29, 30, 34]**:\n- **Sorted Data**: [23, 25, 29, 30, 34]\n- **Median** = Middle value = **29**\n\nFor the dataset **[23, 25, 29, 30]** (even number of data points):\n- **Sorted Data**: [23, 25, 29, 30]\n- **Median** = (25 + 29) / 2 = **27**\n\n### **When to Use**:\n- **Use the median** when your data has **outliers** or is **skewed**.\n- It is not affected by extreme values and provides a better central tendency for skewed distributions.\n\n### **Example Situation**:\n- **House Prices**: If most houses are priced between $200,000 to $400,000 but a few are over $1 million, the median gives a better central value.\n\n---\n\n## **3. Mode**\n### **Definition**:\nThe **mode** is the value that appears most frequently in a dataset. There can be:\n- **No mode** (if no number repeats),\n- **One mode** (unimodal),\n- **Two modes** (bimodal), or\n- **More than two modes** (multimodal).\n\n### **Example**:\nFor the dataset **[1, 2, 2, 3, 4, 4, 4, 5]**:\n- **Mode** = **4** (since it appears most frequently)\n\nFor the dataset **[1, 1, 2, 3, 3]**:\n- **Modes** = **1** and **3** (bimodal)\n\n### **When to Use**:\n- **Use the mode** when you want to identify the **most common value** in a categorical or discrete dataset.\n- It is useful for **qualitative data** where we need to find the most frequent category.\n\n### **Example Situation**:\n- **Customer Feedback**: If most customers rate a product as \"Good\" on a scale (Poor, Fair, Good, Excellent), the mode provides insight into the most common opinion.\n\n---\n\n## **Comparison of Mean, Median, and Mode**\n\n| Measure | Best Used For                        | Characteristics                                | Limitations                       |\n|---------|--------------------------------------|------------------------------------------------|-----------------------------------|\n| **Mean** | Continuous data without outliers    | Considers all data points; easy to calculate   | Affected by extreme values        |\n| **Median** | Skewed data or data with outliers  | Not affected by extreme values; shows middle   | Does not consider all data points |\n| **Mode** | Categorical or most frequent value  | Shows the most common value                    | May not exist or be multiple      |\n\n---\n\n## **Choosing the Right Measure**\n1. **When to use the Mean**:\n   - When the dataset is **normally distributed** without outliers.\n   - Example: Calculating the average test score in a class with no extreme scores.\n\n2. **When to use the Median**:\n   - When the dataset is **skewed** or contains **outliers**.\n   - Example: Finding the central house price in a region with a few very expensive homes.\n\n3. **When to use the Mode**:\n   - When analyzing **categorical data** or looking for the most frequent value.\n   - Example: Determining the most common shoe size sold in a store.\n\nUnderstanding the differences between these measures helps in selecting the appropriate one based on the nature of your data and the goal of your analysis.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 3. Explain the concept of dispersion. How do variance and standard deviation measure the spread of data?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "The concept of **dispersion** refers to the extent to which data points in a dataset are spread out or scattered. It gives us an idea of how much the data values deviate from the central tendency (mean, median, or mode). **Dispersion** helps us understand the **variability** or **consistency** within a dataset.\n\n### **Why is Dispersion Important?**\n- While measures of central tendency (like mean, median, mode) provide a single value that represents the center of the dataset, they do not tell us anything about how the data is spread out.\n- Two datasets may have the same mean but very different spreads. For example:\n  - Dataset A: [10, 10, 10, 10, 10] → Mean = 10, low dispersion (values are the same).\n  - Dataset B: [5, 8, 10, 12, 15] → Mean = 10, higher dispersion (values vary more).\n\n### **Common Measures of Dispersion**\nThe most commonly used measures of dispersion are **range**, **variance**, and **standard deviation**.\n\n## **1. Range**\n- **Definition**: The range is the difference between the maximum and minimum values in the dataset.\n- **Formula**: \n  \\[\n  \\text{Range} = \\text{Maximum Value} - \\text{Minimum Value}\n  \\]\n- **Example**: For the dataset [5, 8, 10, 12, 15], the range is \\(15 - 5 = 10\\).\n- **Limitation**: The range only considers the extreme values and may not reflect the overall spread of the data.\n\n## **2. Variance**\n- **Definition**: Variance measures the **average squared deviation** of each data point from the mean. It quantifies how much the data points differ from the mean.\n- **Formula**:\n  - For a population: \n    \\[\n    \\sigma^2 = \\frac{\\sum (x_i - \\mu)^2}{N}\n    \\]\n  - For a sample: \n    \\[\n    s^2 = \\frac{\\sum (x_i - \\bar{x})^2}{n - 1}\n    \\]\n  Where:\n  - \\( \\sigma^2 \\) = Population variance\n  - \\( s^2 \\) = Sample variance\n  - \\( x_i \\) = Each data point\n  - \\( \\mu \\) = Population mean\n  - \\( \\bar{x} \\) = Sample mean\n  - \\( N \\) = Number of data points in the population\n  - \\( n \\) = Number of data points in the sample\n\n### **Example**:\nConsider the dataset [5, 8, 10, 12, 15]:\n- **Step 1**: Calculate the mean:\n  \\[\n  \\bar{x} = \\frac{5 + 8 + 10 + 12 + 15}{5} = 10\n  \\]\n- **Step 2**: Calculate the squared deviations from the mean:\n  \\[\n  (5-10)^2 = 25, \\quad (8-10)^2 = 4, \\quad (10-10)^2 = 0, \\quad (12-10)^2 = 4, \\quad (15-10)^2 = 25\n  \\]\n- **Step 3**: Calculate the variance:\n  \\[\n  s^2 = \\frac{25 + 4 + 0 + 4 + 25}{5 - 1} = \\frac{58}{4} = 14.5\n  \\]\n\n### **Interpretation**:\n- A higher variance indicates that the data points are more spread out from the mean.\n- A lower variance suggests that the data points are closer to the mean.\n\n## **3. Standard Deviation**\n- **Definition**: The standard deviation is the square root of the variance. It provides a measure of dispersion in the same units as the original data, making it easier to interpret.\n- **Formula**:\n  \\[\n  \\text{Standard Deviation} = \\sqrt{\\text{Variance}}\n  \\]\n  - For a population: \n    \\[\n    \\sigma = \\sqrt{\\frac{\\sum (x_i - \\mu)^2}{N}}\n    \\]\n  - For a sample: \n    \\[\n    s = \\sqrt{\\frac{\\sum (x_i - \\bar{x})^2}{n - 1}}\n    \\]\n\n### **Example**:\nUsing the variance from our previous example (\\( s^2 = 14.5 \\)):\n  \\[\n  s = \\sqrt{14.5} \\approx 3.81\n  \\]\n\n### **Interpretation**:\n- A higher standard deviation indicates a wider spread of data points.\n- A lower standard deviation suggests that the data points are closer to the mean.\n\n## **Comparison of Variance and Standard Deviation**\n| Measure           | Definition                             | Formula                          | Units                 |\n|-------------------|----------------------------------------|----------------------------------|-----------------------|\n| **Variance**      | Average squared deviation from the mean| \\(\\sigma^2\\) or \\(s^2\\)          | Squared units of data |\n| **Standard Deviation** | Square root of variance             | \\(\\sigma\\) or \\(s\\)              | Same units as data    |\n\n### **When to Use Variance and Standard Deviation**:\n- **Variance** is useful in statistical analysis, especially in the context of statistical tests and machine learning algorithms, but its squared units can be hard to interpret.\n- **Standard Deviation** is more interpretable because it is expressed in the same units as the original data. It is commonly used in descriptive statistics.\n\n---\n\n## **Example Situation: Analyzing Test Scores**\n\nSuppose we have test scores for two classes:\n\n- **Class A**: [80, 82, 85, 88, 90]\n- **Class B**: [60, 70, 85, 100, 110]\n\n- **Mean of Class A** = \\(85\\), **Mean of Class B** = \\(85\\).\n- However, **Standard Deviation of Class A** will be much lower than **Class B** because the scores in Class A are closer to the mean, indicating less variability. In contrast, Class B has a wider range of scores, indicating higher variability.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 4. What is a box plot, and what can it tell you about the distribution of data?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A **box plot** (or **box-and-whisker plot**) is a graphical representation of a dataset that provides a summary of its distribution. It displays the **minimum**, **lower quartile (Q1)**, **median (Q2)**, **upper quartile (Q3)**, and **maximum** values, and it can also indicate **outliers**.\n\n### **Components of a Box Plot**\n\n1. **Box**:\n   - The box represents the **interquartile range (IQR)**, which is the middle 50% of the data.\n   - The left edge of the box is the **lower quartile (Q1)** (25th percentile).\n   - The right edge of the box is the **upper quartile (Q3)** (75th percentile).\n   - The line inside the box shows the **median (Q2)** (50th percentile).\n\n2. **Whiskers**:\n   - The whiskers extend from the box to the smallest and largest data points within 1.5 times the **IQR** from **Q1** and **Q3**, respectively.\n   - **Lower whisker**: Extends from **Q1** to the smallest value within 1.5 * IQR below **Q1**.\n   - **Upper whisker**: Extends from **Q3** to the largest value within 1.5 * IQR above **Q3**.\n\n3. **Outliers**:\n   - Data points that lie outside the range defined by the whiskers are considered **outliers**.\n   - These are often marked with dots or asterisks beyond the whiskers.\n\n### **Interpreting a Box Plot**\nA box plot can provide several insights about a dataset, including:\n\n1. **Central Tendency**:\n   - The **median** line inside the box shows the central value of the dataset.\n\n2. **Spread (Dispersion)**:\n   - The **length of the box** (IQR) shows the spread of the middle 50% of the data.\n   - **Longer whiskers** indicate a wider spread of the data, while shorter whiskers indicate a more compact distribution.\n\n3. **Skewness**:\n   - If the **median** is closer to **Q1** or **Q3**, it indicates **skewness**:\n     - **Right-skewed** (positive skew): The median is closer to **Q1**, and the right whisker is longer.\n     - **Left-skewed** (negative skew): The median is closer to **Q3**, and the left whisker is longer.\n\n4. **Outliers**:\n   - Data points outside the whiskers are considered **outliers**. They indicate unusual observations or potential anomalies in the dataset.\n\n### **Example Interpretation**\nLet's interpret a sample box plot:\n\n```\n|-----------------------|\n|            _______    |\n| Q1    Q2    Q3        |\n|_______________________|\n```\n\n- **Minimum Value**: 5\n- **Q1 (25th Percentile)**: 10\n- **Median (50th Percentile, Q2)**: 15\n- **Q3 (75th Percentile)**: 20\n- **Maximum Value**: 30\n- **IQR (Q3 - Q1)**: 10",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np\n\n# Sample Data\ndata = [5, 10, 15, 20, 25, 30]\n\n# Creating Box Plot\nplt.boxplot(data)\nplt.title(\"Box Plot Example\")\nplt.show()",
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": "## 5. Discuss the role of random sampling in making inferences about populations.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **The Role of Random Sampling in Making Inferences About Populations**\n\n**Random sampling** is a fundamental concept in statistics used to draw inferences about a population based on data collected from a smaller group or sample. It plays a crucial role in ensuring that the sample data accurately represents the overall population, allowing researchers to make valid conclusions without studying the entire population.\n\n## **1. What is Random Sampling?**\n- **Definition**: Random sampling is a technique where each individual or element in the population has an **equal** chance of being selected in the sample. \n- **Goal**: The goal is to obtain a representative subset of the population that mirrors its diversity and characteristics, minimizing **bias**.\n\n### **Example of Random Sampling**:\nImagine you want to estimate the average height of college students at your university. Instead of measuring every student, you could randomly select a sample of 200 students from the total population. If done correctly, this sample should give a good estimate of the average height of all students.\n\n## **2. Why Use Random Sampling?**\n\n### **A. Feasibility**:\n- **Cost and Time Efficiency**: It is often impractical or impossible to collect data from an entire population, especially if it is large (e.g., all voters in a country). Random sampling allows researchers to gather relevant information without the expense and time of a full population survey.\n\n### **B. Reducing Bias**:\n- **Minimizes Selection Bias**: Random sampling helps eliminate **selection bias**, where certain individuals have a higher chance of being selected than others. This makes the sample more likely to be representative of the population.\n- **Example**: If you were to only sample students from a specific class, it might not accurately reflect the diversity of the entire university.\n\n### **C. Enables Generalization**:\n- **Generalizable Results**: A well-chosen random sample allows researchers to make **inferences** about the entire population with a known level of confidence. Statistical techniques can be used to estimate how closely the sample statistics approximate the true population parameters.\n\n## **3. How Random Sampling Helps in Making Inferences**\nThe main goal of random sampling is to make inferences about a population. Inferences are conclusions drawn from data, including:\n\n### **A. Estimating Population Parameters**:\n- **Example**: If we randomly sample 100 students to estimate the average height of students at a university, we can use the **sample mean** as an estimate of the **population mean**. Using statistical methods, we can also calculate confidence intervals to quantify the uncertainty of our estimate.\n\n### **B. Hypothesis Testing**:\n- **Example**: Suppose we want to test whether a new teaching method is more effective than the standard method. By randomly assigning students to the new or standard method groups, we can use **hypothesis testing** to determine if any observed difference in performance is statistically significant.\n\n### **C. Reducing Sampling Error**:\n- **Sampling Error**: This is the difference between a sample statistic (like the sample mean) and the true population parameter (like the population mean). Random sampling reduces the risk of systematic sampling error and allows us to estimate the variability in our sample results.\n- **Law of Large Numbers**: As the sample size increases, the sample mean gets closer to the population mean, reducing sampling error.\n\n## **4. Types of Random Sampling**\n\n### **A. Simple Random Sampling**:\n- **Definition**: Every member of the population has an equal chance of being selected.\n- **Example**: Drawing names from a hat where each name represents an individual from the population.\n\n### **B. Stratified Random Sampling**:\n- **Definition**: The population is divided into subgroups (strata) based on certain characteristics, and random samples are taken from each stratum.\n- **Example**: Dividing a student population by grade level (freshman, sophomore, junior, senior) and then randomly sampling from each grade level.\n\n### **C. Systematic Random Sampling**:\n- **Definition**: Every nth member of the population is selected after randomly choosing a starting point.\n- **Example**: If you have a list of 1,000 students and want to sample 100, you might select every 10th student after randomly picking a starting point.\n\n### **D. Cluster Random Sampling**:\n- **Definition**: The population is divided into clusters, and entire clusters are randomly selected.\n- **Example**: Dividing a city into neighborhoods (clusters) and randomly selecting a few neighborhoods to survey every household.\n\n## **5. Limitations of Random Sampling**\nWhile random sampling is a powerful tool, it has some limitations:\n\n### **A. Sampling Bias**:\n- If the sampling method is flawed or if there are errors in selecting the sample, it can still introduce bias.\n- **Example**: Using a phone survey may exclude people without phones or those who do not answer calls, leading to biased results.\n\n### **B. Non-Response Bias**:\n- If certain individuals chosen for the sample do not respond or participate, it may result in a sample that is not representative of the population.\n- **Example**: If only 50% of those selected in a survey respond, the results may not accurately reflect the entire population.\n\n### **C. Cost and Practicality**:\n- In some cases, true random sampling may be difficult or costly to implement, especially in large or inaccessible populations.\n\n## **Conclusion**\nRandom sampling is a key technique in statistics because it allows us to make reliable inferences about a population based on a sample. By minimizing bias and reducing sampling error, it ensures that the conclusions drawn from the sample are valid and generalizable to the broader population.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 6. Explain the concept of skewness and its types. How does skewness affect the interpretation of data?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **Understanding Skewness in Data**\n\n**Skewness** is a statistical measure that describes the **asymmetry** or **lack of symmetry** in the distribution of data. It tells us whether the data is skewed towards the left or right of the mean, affecting how we interpret the data's central tendency and spread.\n\n### **Key Concepts of Skewness:**\n1. **Symmetric Distribution**: \n   - When the data is evenly distributed around the mean, with a mirror image on both sides, it has **no skewness**.\n   - Example: In a normal distribution (bell-shaped curve), the mean, median, and mode are equal, and skewness is **0**.\n\n2. **Positive Skewness (Right Skewed)**:\n   - The **tail on the right side** of the distribution is longer or fatter than the left side.\n   - **Mean > Median > Mode**.\n   - **Example**: Income distribution, where a small number of high-income values stretch the tail to the right. Most people have lower to average income, with fewer individuals having extremely high income.\n\n3. **Negative Skewness (Left Skewed)**:\n   - The **tail on the left side** of the distribution is longer or fatter than the right side.\n   - **Mean < Median < Mode**.\n   - **Example**: Age at retirement, where a few early retirees lower the age tail on the left, while most people retire around the average or later ages.\n\n### **Types of Skewness:**\n\n| Type of Skewness  | Description                                 | Characteristics                        |\n|-------------------|---------------------------------------------|----------------------------------------|\n| **Symmetric**     | No skewness, data evenly distributed        | Mean = Median = Mode                   |\n| **Positive Skew** | Right-skewed, longer tail on the right side | Mean > Median > Mode                   |\n| **Negative Skew** | Left-skewed, longer tail on the left side   | Mean < Median < Mode                   |\n\n### **Visual Representation:**\n\n1. **Symmetric Distribution**:\n```\n      ^\n     / \\\n    /   \\\n   /     \\\n  /_______\\\n```\n\n2. **Positively Skewed (Right Skewed)**:\n```\n      ^\n     /|\n    / |\n   /  |_________\n  /             \\__\n /_________________\\\n```\n\n3. **Negatively Skewed (Left Skewed)**:\n```\n      ^\n    __/|\n   /   |\n  /    |_________\n /               \\\n/_________________\\\n```\n\n### **How Skewness Affects the Interpretation of Data**:\n\n1. **Impact on Measures of Central Tendency**:\n   - **Symmetric Distribution**: Mean, median, and mode are close to each other.\n   - **Positively Skewed**: The **mean** is pulled in the direction of the long tail (to the right), making it larger than the median.\n   - **Negatively Skewed**: The **mean** is dragged towards the long left tail, making it smaller than the median.\n\n   **Example**:\n   - For a **right-skewed** dataset of house prices: \\$100,000, \\$150,000, \\$200,000, \\$250,000, \\$5,000,000\n     - **Mean** = \\$1,140,000\n     - **Median** = \\$200,000\n     - The mean is much higher due to a few very expensive houses (right skew).\n\n2. **Impact on Data Interpretation**:\n   - **Right Skew (Positive Skew)**:\n     - The data has a lot of low or average values with a few exceptionally high values.\n     - Median may be a better measure of central tendency because it is less influenced by extreme values.\n   - **Left Skew (Negative Skew)**:\n     - The data has a lot of high values with a few extremely low values.\n     - Median is often preferred to represent the center as it is less affected by the skewed lower tail.\n\n3. **Impact on Statistical Analysis**:\n   - **Normal Distribution Assumption**: Many statistical tests assume normality (symmetry) of the data. When data is skewed, it might violate this assumption, affecting the results of parametric tests like **t-tests** and **ANOVA**.\n   - **Transformations**: To handle skewness, transformations such as **logarithmic**, **square root**, or **Box-Cox** can be applied to make the data more symmetric.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 7. What is the interquartile range (IQR), and how is it used to detect outliers?",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **Interquartile Range (IQR): Definition and Outlier Detection**\n\nThe **Interquartile Range (IQR)** is a measure of statistical dispersion, representing the range within which the **middle 50%** of the data lies. It is used to understand the **spread** of the central portion of a dataset and is a common method for **detecting outliers**.\n\n### **How to Calculate IQR**:\n\n1. **Order the Data**: Arrange the dataset in ascending order.\n2. **Find the Quartiles**:\n   - **Q1 (First Quartile)**: The median of the lower half of the data (25th percentile).\n   - **Q3 (Third Quartile)**: The median of the upper half of the data (75th percentile).\n3. **Calculate IQR**:\n   \\[\n   \\text{IQR} = Q3 - Q1\n   \\]\n\n### **Example**:\n\nConsider the dataset: **[2, 4, 5, 7, 9, 10, 12, 15, 18, 20]**.\n\n- **Q1** = Median of the lower half: (4 + 5)/2 = **4.5**\n- **Q3** = Median of the upper half: (15 + 18)/2 = **16.5**\n- **IQR** = Q3 - Q1 = **16.5 - 4.5** = **12**\n\n### **Using IQR to Detect Outliers**:\n\nOutliers are data points that fall **significantly** outside the expected range. We use the IQR to identify outliers using the following formula:\n\n- **Lower Bound**: \\( Q1 - 1.5 \\times \\text{IQR} \\)\n- **Upper Bound**: \\( Q3 + 1.5 \\times \\text{IQR} \\)\n\nAny data points below the lower bound or above the upper bound are considered **outliers**.\n\n### **Example Continued**:\n\n- **Lower Bound**: \\( 4.5 - 1.5 \\times 12 = -13.5 \\)\n- **Upper Bound**: \\( 16.5 + 1.5 \\times 12 = 34.5 \\)\n\n- **Outliers**: Any data points < -13.5 or > 34.5 are outliers. In this dataset, there are no outliers as all values lie within the range [-13.5, 34.5].\n\n### **Why Use IQR for Outlier Detection?**\n\n- **Robust to Skewed Data**: Unlike the mean and standard deviation, the IQR is not affected by extreme values, making it more reliable for skewed data.\n- **Focus on Middle 50%**: By concentrating on the central 50% of the data, the IQR effectively highlights the expected range of the data.\n\n### **Visualization**:\n\nIn a **box plot**, the IQR is represented by the length of the **box** (from Q1 to Q3). Outliers are typically shown as **individual points** outside the \"whiskers,\" which extend to the lowest and highest data points within the 1.5 × IQR range.\n\n**Summary**: \n- The IQR helps measure the spread of the middle 50% of data and detect outliers.\n- Values beyond \\(1.5 \\times \\text{IQR}\\) from Q1 or Q3 are considered outliers, highlighting unusually high or low observations.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 8. Discuss the conditions under which the binomial distribution is used.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **Binomial Distribution: Definition and Conditions**\n\nThe **binomial distribution** is a **discrete probability distribution** that models the number of **successes** in a fixed number of **independent** trials, where each trial has exactly two possible outcomes: **success** or **failure**.\n\n### **Conditions for Using the Binomial Distribution**:\n\nThe binomial distribution is appropriate under the following conditions:\n\n1. **Fixed Number of Trials (n)**:\n   - There is a predetermined number of trials, denoted as \\( n \\).\n   - Example: Flipping a coin **10 times**, rolling a die **20 times**.\n\n2. **Two Possible Outcomes**:\n   - Each trial has exactly two possible outcomes: **success** (e.g., heads, correct answer) and **failure** (e.g., tails, incorrect answer).\n   - Example: In a coin toss, \"heads\" can be considered a success and \"tails\" a failure.\n\n3. **Constant Probability of Success (p)**:\n   - The probability of success, denoted as \\( p \\), remains the **same** for each trial.\n   - Example: The probability of getting heads in a fair coin toss is always \\( p = 0.5 \\).\n\n4. **Independence of Trials**:\n   - The outcome of one trial does not affect the outcome of any other trial.\n   - Example: Each coin toss is independent of previous or future tosses.\n\n### **Binomial Probability Formula**:\n\nThe probability of observing exactly \\( k \\) successes in \\( n \\) trials is given by:\n\n\\[\nP(X = k) = \\binom{n}{k} p^k (1 - p)^{n - k}\n\\]\n\nWhere:\n- \\( \\binom{n}{k} \\) is the **binomial coefficient**: \\( \\binom{n}{k} = \\frac{n!}{k!(n-k)!} \\)\n- \\( p \\) is the probability of success on a single trial.\n- \\( 1 - p \\) is the probability of failure.\n- \\( k \\) is the number of successes.\n\n### **Example**:\n\n**Problem**: What is the probability of getting exactly **3 heads** in **5 flips** of a fair coin?\n\n- \\( n = 5 \\) (number of trials)\n- \\( p = 0.5 \\) (probability of success, i.e., getting heads)\n- \\( k = 3 \\) (number of successes)\n\n\\[\nP(X = 3) = \\binom{5}{3} (0.5)^3 (0.5)^{2} = 10 \\times 0.125 \\times 0.25 = 0.3125\n\\]\n\nThe probability of getting exactly 3 heads in 5 flips is **0.3125**.\n\n### **When to Use the Binomial Distribution**:\n\nThe binomial distribution is useful when you want to model scenarios like:\n\n- **Quality control**: Determining the number of defective products in a batch.\n- **Survey analysis**: Estimating the number of people who will answer \"yes\" to a yes/no question.\n- **Game outcomes**: Calculating the probability of winning a certain number of games out of a fixed series.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 9. Explain the properties of the normal distribution and the empirical rule (68-95-99.7 rule).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **Normal Distribution: Properties and the Empirical Rule**\n\nThe **normal distribution**, also known as the **Gaussian distribution**, is a continuous probability distribution that is symmetric and bell-shaped. It is one of the most important distributions in statistics because many natural phenomena and measurement errors tend to follow this pattern.\n\n### **Properties of the Normal Distribution**:\n\n1. **Symmetry**:\n   - The normal distribution is perfectly **symmetric** around its **mean** (\\(\\mu\\)).\n   - The left half of the curve is a mirror image of the right half.\n\n2. **Mean, Median, and Mode**:\n   - In a normal distribution, the **mean** (\\(\\mu\\)), **median**, and **mode** are all equal and located at the center of the distribution.\n\n3. **Bell-Shaped Curve**:\n   - The curve is **bell-shaped**, where most of the data points are concentrated around the mean, and the frequencies decrease as you move away from the mean.\n\n4. **Asymptotic**:\n   - The tails of the normal distribution approach, but never touch, the horizontal axis. This means the probability of extreme values is low but not zero.\n\n5. **Defined by Mean and Standard Deviation**:\n   - The shape and spread of the normal distribution are determined by two parameters:\n     - **Mean** (\\(\\mu\\)): Determines the center of the distribution.\n     - **Standard Deviation** (\\(\\sigma\\)): Determines the spread or width of the distribution. A larger \\(\\sigma\\) results in a wider and flatter curve.\n\n### **The Empirical Rule (68-95-99.7 Rule)**:\n\nThe **empirical rule** provides a quick way to understand the spread of data in a normal distribution. It states that:\n\n1. **68% of Data**:\n   - Approximately **68%** of the data falls within **one standard deviation** (\\(\\mu \\pm \\sigma\\)) of the mean.\n\n2. **95% of Data**:\n   - About **95%** of the data lies within **two standard deviations** (\\(\\mu \\pm 2\\sigma\\)) of the mean.\n\n3. **99.7% of Data**:\n   - Nearly **99.7%** of the data falls within **three standard deviations** (\\(\\mu \\pm 3\\sigma\\)) of the mean.\n\n### **Visual Representation**:\n\n```\n           -3σ   -2σ   -1σ    μ    +1σ   +2σ   +3σ\n             |----|----|----|----|----|----|----|\n              0.1%  2.1% 13.6% 34% 34% 13.6% 2.1% 0.1%\n            \\__________________________/        \n                     68%\n            \\________________________________________/\n                               95%\n            \\__________________________________________________________/\n                                         99.7%\n```\n\n### **Example**:\n\nIf the heights of a group of people are normally distributed with a mean (\\(\\mu\\)) of 170 cm and a standard deviation (\\(\\sigma\\)) of 10 cm:\n\n- **68%** of people have heights between **160 cm** (170 - 10) and **180 cm** (170 + 10).\n- **95%** of people have heights between **150 cm** (170 - 2×10) and **190 cm** (170 + 2×10).\n- **99.7%** of people have heights between **140 cm** (170 - 3×10) and **200 cm** (170 + 3×10).\n\n### **Importance of the Normal Distribution**:\n\n1. **Central Limit Theorem**:\n   - The **central limit theorem** states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, regardless of the original distribution of the population.\n\n2. **Statistical Analysis**:\n   - Many statistical tests, confidence intervals, and hypothesis testing methods are based on the assumption of normality.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 10. Provide a real-life example of a Poisson process and calculate the probability for a specific event.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **Poisson Process: Real-Life Example and Calculation**\n\nThe **Poisson process** is a statistical model used to describe the occurrence of **rare, random events** that happen **independently** and at a **constant average rate** over a given interval of time or space.\n\n### **Real-Life Example**:\n\n**Example**: \nImagine a call center that receives an average of **3 calls per minute**. We want to calculate the probability that the call center will receive **5 calls** in a specific minute.\n\n### **Poisson Distribution Formula**:\n\nThe **Poisson probability** of observing exactly \\( k \\) events in a fixed interval is given by:\n\n\\[\nP(X = k) = \\frac{e^{-\\lambda} \\lambda^k}{k!}\n\\]\n\nWhere:\n- \\( X \\) is the random variable representing the number of events (calls).\n- \\( k \\) is the actual number of events we want to find the probability for (\\( k = 5 \\) in this case).\n- \\( \\lambda \\) (lambda) is the average number of events in the interval (\\( \\lambda = 3 \\) calls per minute).\n- \\( e \\) is the base of the natural logarithm, approximately equal to 2.71828.\n\n### **Calculation**:\n\nGiven:\n- \\( \\lambda = 3 \\)\n- \\( k = 5 \\)\n\nSubstitute these values into the formula:\n\n\\[\nP(X = 5) = \\frac{e^{-3} \\times 3^5}{5!}\n\\]\n\nLet's compute this step by step:\n\n1. **Calculate \\( e^{-3} \\)**:\n   \\[\n   e^{-3} \\approx 0.0498\n   \\]\n\n2. **Calculate \\( 3^5 \\)**:\n   \\[\n   3^5 = 243\n   \\]\n\n3. **Calculate \\( 5! \\)** (factorial of 5):\n   \\[\n   5! = 5 \\times 4 \\times 3 \\times 2 \\times 1 = 120\n   \\]\n\n4. **Compute the probability**:\n   \\[\n   P(X = 5) = \\frac{0.0498 \\times 243}{120} \\approx 0.1008\n   \\]\n\n### **Result**:\n\nThe probability that the call center will receive **exactly 5 calls** in a specific minute is **0.1008** or **10.08%**.\n\n### **When to Use the Poisson Process**:\n\nThe Poisson process is ideal for modeling events that:\n1. Occur **randomly** and **independently**.\n2. Happen at a **constant average rate**.\n3. Are **rare** or infrequent relative to the time interval.\n\n### **Real-Life Applications**:\n- **Traffic**: Number of cars passing through a toll booth in an hour.\n- **Customer Service**: Number of customer service requests per day.\n- **Healthcare**: Number of emergency arrivals at a hospital per hour.\n- **Natural Phenomena**: Number of earthquakes in a region per year.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 11. Explain what a random variable is and differentiate between discrete and continuous random variables.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **Random Variable: Definition**\n\nA **random variable** is a numerical value that represents the outcome of a random experiment. It assigns a real number to each possible outcome of a random process. Random variables are used to quantify and describe the results of random phenomena in statistics and probability theory.\n\n### **Types of Random Variables**:\n\nThere are two main types of random variables:\n\n1. **Discrete Random Variables**\n2. **Continuous Random Variables**\n\n### **1. Discrete Random Variables**\n\nA **discrete random variable** can take on a **finite** or **countable** number of distinct values. Each value has an associated probability, and the sum of these probabilities is 1.\n\n#### **Characteristics**:\n- Values are **countable** (e.g., 0, 1, 2, 3...).\n- The probabilities of specific outcomes can be calculated using a **probability mass function (PMF)**.\n- Examples include the number of heads in a series of coin flips, number of students in a class, or the outcome of rolling a die.\n\n#### **Example**:\n- Let \\( X \\) be the random variable representing the number of heads when flipping a coin twice. \n- Possible values of \\( X \\): {0, 1, 2}\n- Probabilities: \\( P(X = 0) = 0.25 \\), \\( P(X = 1) = 0.5 \\), \\( P(X = 2) = 0.25 \\)\n\n### **2. Continuous Random Variables**\n\nA **continuous random variable** can take on an **infinite** number of possible values within a given range. These variables are not countable and are instead described using intervals.\n\n#### **Characteristics**:\n- Values are **uncountable** and can take any value within a range (e.g., 2.1, 2.15, 2.156...).\n- The probability of any exact value is **zero**; instead, we use a **probability density function (PDF)** to determine the probability over an interval.\n- Examples include the height of individuals, time taken to complete a task, or the temperature at a specific time.\n\n#### **Example**:\n- Let \\( Y \\) be the random variable representing the height of students in a class. \n- Possible values of \\( Y \\): Any real number within a range, such as 150 cm to 200 cm.\n\n### **Key Differences Between Discrete and Continuous Random Variables**:\n\n| **Feature**            | **Discrete Random Variable**                   | **Continuous Random Variable**            |\n|------------------------|-------------------------------------------------|------------------------------------------|\n| **Values**             | Finite or countable                            | Infinite or uncountable                  |\n| **Probability**        | Calculated for specific values (PMF)           | Calculated for intervals (PDF)           |\n| **Example**            | Number of cars in a parking lot                | Weight of a randomly selected person     |\n| **Exact Value Probability** | Non-zero for specific values                | Zero for specific values, positive over intervals |\n\n### **Visual Representation**:\n\n1. **Discrete Random Variable**: Can be visualized as a series of distinct points on a graph where each point represents the probability of a specific outcome.\n   - Example: A bar chart showing the probabilities of rolling a die (1 to 6).\n\n2. **Continuous Random Variable**: Represented by a smooth curve where the area under the curve over an interval represents the probability.\n   - Example: A bell-shaped curve of the normal distribution for heights.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## 12. Provide an example dataset, calculate both covariance and correlation, and interpret the results.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### **Example Dataset, Covariance, and Correlation Calculation**\n\nLet's start with a small dataset and calculate both the **covariance** and **correlation** between two variables: **Hours Studied** and **Exam Scores**. \n\n### **Example Dataset**:\n\n| Student | Hours Studied (X) | Exam Score (Y) |\n|---------|-------------------|----------------|\n| 1       | 2                 | 65             |\n| 2       | 3                 | 70             |\n| 3       | 5                 | 75             |\n| 4       | 7                 | 85             |\n| 5       | 8                 | 90             |\n\n### **Step 1: Calculate Covariance**\n\n**Covariance** is a measure of how much two variables vary together. It can be positive (indicating a positive relationship), negative (indicating a negative relationship), or zero (no relationship).\n\nThe formula for sample covariance is:\n\n\\[\n\\text{Cov}(X, Y) = \\frac{\\sum (X_i - \\bar{X})(Y_i - \\bar{Y})}{n - 1}\n\\]\n\nWhere:\n- \\( X_i \\) and \\( Y_i \\) are individual sample points.\n- \\( \\bar{X} \\) and \\( \\bar{Y} \\) are the means of \\( X \\) and \\( Y \\).\n- \\( n \\) is the number of data points.\n\nLet's calculate this step by step.\n\n#### **Calculating Means**:\n\\[\n\\bar{X} = \\frac{2 + 3 + 5 + 7 + 8}{5} = 5\n\\]\n\\[\n\\bar{Y} = \\frac{65 + 70 + 75 + 85 + 90}{5} = 77\n\\]\n\n#### **Calculate Covariance**:\n\n\\[\n\\text{Cov}(X, Y) = \\frac{(2-5)(65-77) + (3-5)(70-77) + (5-5)(75-77) + (7-5)(85-77) + (8-5)(90-77)}{5-1}\n\\]\n\n\\[\n\\text{Cov}(X, Y) = \\frac{(-3)(-12) + (-2)(-7) + (0)(-2) + (2)(8) + (3)(13)}{4}\n\\]\n\n\\[\n\\text{Cov}(X, Y) = \\frac{36 + 14 + 0 + 16 + 39}{4}\n\\]\n\n\\[\n\\text{Cov}(X, Y) = \\frac{105}{4} = 26.25\n\\]\n\n**Interpretation**:\n- The positive covariance (26.25) suggests that there is a **positive relationship** between hours studied and exam scores, meaning as hours studied increase, exam scores tend to increase as well.\n\n### **Step 2: Calculate Correlation**\n\n**Correlation** measures the **strength and direction** of a linear relationship between two variables. It is standardized and ranges from **-1** to **1**:\n\n- **+1**: Perfect positive linear relationship.\n- **0**: No linear relationship.\n- **-1**: Perfect negative linear relationship.\n\nThe formula for the Pearson correlation coefficient \\( r \\) is:\n\n\\[\nr = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n\\]\n\nWhere:\n- \\( \\sigma_X \\) and \\( \\sigma_Y \\) are the standard deviations of \\( X \\) and \\( Y \\).\n\n#### **Calculate Standard Deviations**:\n\n1. **Standard Deviation of \\( X \\)**:\n   \\[\n   \\sigma_X = \\sqrt{\\frac{\\sum (X_i - \\bar{X})^2}{n - 1}}\n   \\]\n   \\[\n   \\sigma_X = \\sqrt{\\frac{(-3)^2 + (-2)^2 + (0)^2 + (2)^2 + (3)^2}{4}}\n   \\]\n   \\[\n   \\sigma_X = \\sqrt{\\frac{9 + 4 + 0 + 4 + 9}{4}}\n   \\]\n   \\[\n   \\sigma_X = \\sqrt{\\frac{26}{4}} = \\sqrt{6.5} \\approx 2.55\n   \\]\n\n2. **Standard Deviation of \\( Y \\)**:\n   \\[\n   \\sigma_Y = \\sqrt{\\frac{(-12)^2 + (-7)^2 + (-2)^2 + (8)^2 + (13)^2}{4}}\n   \\]\n   \\[\n   \\sigma_Y = \\sqrt{\\frac{144 + 49 + 4 + 64 + 169}{4}}\n   \\]\n   \\[\n   \\sigma_Y = \\sqrt{\\frac{430}{4}} = \\sqrt{107.5} \\approx 10.37\n   \\]\n\n#### **Calculate Correlation**:\n\n\\[\nr = \\frac{26.25}{2.55 \\times 10.37} = \\frac{26.25}{26.44} \\approx 0.99\n\\]\n\n**Interpretation**:\n- The correlation coefficient \\( r \\approx 0.99 \\) indicates a **strong positive linear relationship** between hours studied and exam scores.\n\n### **Summary**:\n- **Covariance**: 26.25 (positive, indicating a positive relationship).\n- **Correlation**: 0.99 (strong positive linear relationship).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}